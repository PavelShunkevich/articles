{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b49a58-e233-4da1-a668-7e9e0f8e694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "from typing import Callable, Optional\n",
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f82dee66-bcf9-4dd0-8d0c-fbbbfc5530dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_and_std(loader: DataLoader, dim: list, device=\"cpu\") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Вычисление среднего значения и стандартного отклонения в наборе данных.\n",
    "\n",
    "    Args:\n",
    "        loader (DataLoader): DataLoader для итерации по набору данных\n",
    "        dim (list): Размерности, по которым будут считатья значения\n",
    "        device (str): Устройство, на котором выполняются вычисления (\"cpu\" или \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, torch.Tensor]: Кортеж, содержащий тензоры среднего значения и стандартного отклонения.\n",
    "    \"\"\"\n",
    "    # 1 Создаем список из всех тензоров\n",
    "    inputs_list = []\n",
    "    for inputs, _ in loader:\n",
    "        inputs_list.append(inputs)\n",
    "\n",
    "    # 2 Соединяем все тензоры в один большой тензор\n",
    "    all_inputs = torch.cat(inputs_list, dim=0).float().to(device)  # Преобразуем в float и перемещаем на устройство\n",
    "\n",
    "    # 3 Вычисляем mean и std\n",
    "    mean = torch.mean(all_inputs, dim=dim)\n",
    "    std = torch.std(all_inputs, dim=dim)\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    A class to evaluate a PyTorch model on given datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, device: torch.device):\n",
    "        \"\"\"\n",
    "        Initializes the ModelEvaluator.\n",
    "\n",
    "        Args:\n",
    "            model: The PyTorch model to evaluate.\n",
    "            device: The device to perform evaluation on (e.g., 'cuda' or 'cpu').\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.to(self.device)  # Move model to the specified device\n",
    "\n",
    "    def evaluate_dataset(self, loader: DataLoader) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluates the model on a given dataset and returns a dictionary of metrics.\n",
    "\n",
    "        Args:\n",
    "            loader: The DataLoader for the dataset.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing evaluation metrics, e.g., {\"accuracy\": 0.95}.\n",
    "        \"\"\"\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, target in loader:\n",
    "                inputs, target = inputs.to(self.device), target.to(self.device)  # Move data to device\n",
    "                outputs = self.model(inputs)\n",
    "                _, predicted = torch.max(outputs, dim=1)  # Get predictions\n",
    "                correct += (predicted == target).sum().item()  # Count correct predictions\n",
    "                total += target.size(0)  # Count total number of samples\n",
    "\n",
    "        accuracy: float = correct / total\n",
    "        return {\"accuracy\": accuracy}\n",
    "\n",
    "    def evaluate(self, train_loader: DataLoader, val_loader: DataLoader) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Evaluates the model on train and validation datasets and returns a dictionary of metrics.\n",
    "\n",
    "        Args:\n",
    "            train_loader: The DataLoader for the training dataset.\n",
    "            val_loader: The DataLoader for the validation dataset.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing evaluation metrics for both training and validation datasets,\n",
    "            e.g., {\"train\": {\"accuracy\": 0.90}, \"val\": {\"accuracy\": 0.95}}.\n",
    "        \"\"\"\n",
    "        print(f\"Evaluating on device {self.device}.\")\n",
    "        metrics = {}\n",
    "        metrics[\"train\"] = self.evaluate_dataset(train_loader)\n",
    "        metrics[\"val\"] = self.evaluate_dataset(val_loader)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    A class to encapsulate the training loop for a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model to train.\n",
    "        optimizer: The optimizer to use for training.\n",
    "        loss_fn: The loss function to use.\n",
    "        train_loader: The DataLoader for the training data.\n",
    "        device: The device to train on (CPU or GPU).\n",
    "        clip_grad_norm: Optional value to clip gradients to. Defaults to None.\n",
    "        print_interval:  How often to print the training loss. Defaults to 10.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        loss_fn: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        device: torch.device,\n",
    "        clip_grad_norm: Optional[float] = None,\n",
    "        print_interval: int = 10,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_loader = train_loader\n",
    "        self.device = device\n",
    "        self.clip_grad_norm = clip_grad_norm\n",
    "        self.print_interval = print_interval\n",
    "\n",
    "        self.model.to(self.device)  # Move the model to the device in the constructor\n",
    "\n",
    "    def train_one_batch(self, inputs: torch.Tensor, target: torch.Tensor) -> float:\n",
    "        \"\"\"Trains the model on a single batch of data.\n",
    "\n",
    "        Args:\n",
    "            inputs: The input tensor.\n",
    "            target: The target tensor.\n",
    "\n",
    "        Returns:\n",
    "            The loss value for the batch.\n",
    "        \"\"\"\n",
    "        self.model.train()  # Ensure the model is in training mode\n",
    "\n",
    "        self.optimizer.zero_grad(set_to_none=True)  # More efficient if possible\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss_fn(outputs, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if self.clip_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_grad_norm)  # Gradient clipping\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def train_epoch(self, epoch_num: int = 0) -> float:\n",
    "        \"\"\"Trains the model for one epoch.\n",
    "\n",
    "        Args:\n",
    "            epoch_num: The current epoch number (for logging).  Defaults to 0.\n",
    "\n",
    "        Returns:\n",
    "            The average loss for the epoch.\n",
    "        \"\"\"\n",
    "        self.model.train()  # Ensure the model is in training mode\n",
    "        loss_train = 0.0\n",
    "        num_batches = len(self.train_loader)\n",
    "        for batch_idx, (inputs, target) in enumerate(self.train_loader):\n",
    "            inputs = inputs.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            loss_train += self.train_one_batch(inputs, target)\n",
    "\n",
    "        return loss_train / num_batches\n",
    "\n",
    "    def training_loop(self, n_epochs: int) -> None:\n",
    "        \"\"\"Executes the main training loop.\n",
    "\n",
    "        Args:\n",
    "            n_epochs: The number of epochs to train for.\n",
    "        \"\"\"\n",
    "        print(f\"Training on device {self.device}.\")\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            avg_loss = self.train_epoch(epoch)\n",
    "\n",
    "            if epoch == 1 or epoch % self.print_interval == 0:\n",
    "                print(f\"{datetime.datetime.now()} Epoch {epoch}, Training loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1d22b-aadb-4588-861b-ade803ead6cd",
   "metadata": {},
   "source": [
    "# 1. Computer Vision - CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f90f32-029c-4577-85f7-4f508c02a816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.2860])\n",
      "Std Dev: tensor([0.3530])\n",
      "Training on device cuda.\n",
      "Training on device cuda.\n",
      "2025-02-18 19:16:43.444979 Epoch 1, Training loss: 0.5407\n",
      "2025-02-18 19:16:50.104656 Epoch 2, Training loss: 0.3443\n",
      "2025-02-18 19:16:57.410519 Epoch 3, Training loss: 0.3188\n",
      "2025-02-18 19:17:04.791759 Epoch 4, Training loss: 0.3063\n",
      "2025-02-18 19:17:12.339287 Epoch 5, Training loss: 0.2939\n",
      "2025-02-18 19:17:19.785564 Epoch 6, Training loss: 0.2862\n",
      "2025-02-18 19:17:27.051387 Epoch 7, Training loss: 0.2785\n",
      "2025-02-18 19:17:34.310270 Epoch 8, Training loss: 0.2759\n",
      "2025-02-18 19:17:41.695521 Epoch 9, Training loss: 0.2750\n",
      "2025-02-18 19:17:49.040341 Epoch 10, Training loss: 0.2693\n",
      "Evaluating on device cuda.\n",
      "{'train': {'accuracy': 0.93105}, 'val': {'accuracy': 0.9066}}\n"
     ]
    }
   ],
   "source": [
    "# 0 Создаем словарь с классами\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_names_dict = dict(zip(range(len(class_names)), class_names))\n",
    "\n",
    "# 1 Загрузка и подготовка данных (без нормализации), получение Mean и Std\n",
    "trainset= torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]))\n",
    "# 1.1 создаем dataloader\n",
    "dataloader = DataLoader(trainset, batch_size=64, shuffle=False, num_workers=2)\n",
    "# 1.2 считаем mean и std\n",
    "mean, std = compute_mean_and_std(dataloader, [0,2,3])\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std Dev: {std}\")\n",
    "\n",
    "# 2 Загрузка и подготовка данных (с нормализацией)\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])) # Тренировочный набор\n",
    "valset = datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])) # Валидационный набор\n",
    "\n",
    "# 3 Создаем dataloders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "# 4 Выбираем устройство для обучения (GPU, если доступен, иначе CPU)\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "# 5 Определяем архитектуру нейронной сети\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,28, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(28,56, kernel_size=3, padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.fc1 = nn.Linear(56*14*14, 112)\n",
    "        self.fc2 = nn.Linear(112, 10)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(self.dropout1(x),2)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = nn.functional.relu(self.fc1(self.dropout2(x)))\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "# 6 Настройка модели, оптимизатора и функции потерь\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 7.1 Создание и настройка тренера (Trainer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    device=device,\n",
    "    clip_grad_norm=1.0,\n",
    "    print_interval=1,\n",
    ")\n",
    "# 7.2 Запуск процесса обучения\n",
    "trainer.training_loop(n_epochs=10)\n",
    "\n",
    "# 8 Оценка обученной модели\n",
    "evaluator = ModelEvaluator(model, device)\n",
    "metrics = evaluator.evaluate(train_loader, val_loader)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441ce4f-354c-4bf4-8803-831076f95b12",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da2b5ee-e57c-4596-a4bb-afd2eff3cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real answer: Coat\n",
      "Model answer: Coat\n",
      "\n",
      "Result:\n",
      "Model response is correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_number = 10\n",
    "image, label = valset[image_number]\n",
    "print(f\"Class: {class_names_dict[label]}\")\n",
    "plt.imshow(image.squeeze(),cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# predict\n",
    "outputs = model(valset[image_number][0].to(device).unsqueeze(0))\n",
    "_, predicted = torch.max(outputs, dim=1)\n",
    "\n",
    "# validate\n",
    "real_answer = class_names_dict[valset[image_number][1]]\n",
    "model_answer = class_names_dict[predicted.item()]\n",
    "if real_answer == model_answer:\n",
    "    result = 'correct'\n",
    "else:\n",
    "    result = 'incorrect'\n",
    "    \n",
    "print(f\"\"\"\n",
    "Real answer: {real_answer}\n",
    "Model answer: {model_answer}\n",
    "\n",
    "Result:\n",
    "Model response is {result}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d7f83-78ed-4ce6-a0aa-dc4ff3fef73d",
   "metadata": {},
   "source": [
    "# 2. Natural Language Processing (NLP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068101ea-baf0-4b75-bf37-0cb735e25f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
